# --- START OF FILE category_auto_crawler.py ---

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import os
import re # å¼•å…¥æ­£åˆ™æ¨¡å—ï¼Œç”¨äºæå–æ˜Ÿæ˜Ÿæ•°å­—

TARGET_CATEGORIES = [
    "https://www.trustpilot.com/categories/animals_pets?sort=reviews_count",
    "https://www.trustpilot.com/categories/events_entertainment?sort=reviews_count",
    "https://www.trustpilot.com/categories/home_garden?sort=reviews_count",
    "https://www.trustpilot.com/categories/restaurants_bars?sort=reviews_count",
    "https://www.trustpilot.com/categories/beauty_wellbeing?sort=reviews_count",
    "https://www.trustpilot.com/categories/food_beverages_tobacco?sort=reviews_count",
    "https://www.trustpilot.com/categories/home_services?sort=reviews_count",
    "https://www.trustpilot.com/categories/shopping_fashion?sort=reviews_count",
    "https://www.trustpilot.com/categories/business_services?sort=reviews_count",
    "https://www.trustpilot.com/categories/legal_services_government?sort=reviews_count",
    "https://www.trustpilot.com/categories/sports?sort=reviews_count",
    "https://www.trustpilot.com/categories/health_medical?sort=reviews_count",
    "https://www.trustpilot.com/categories/construction_manufactoring?sort=reviews_count",
    "https://www.trustpilot.com/categories/media_publishing?sort=reviews_count",
    "https://www.trustpilot.com/categories/travel_vacation?sort=reviews_count",
    "https://www.trustpilot.com/categories/money_insurance?sort=reviews_count",
    "https://www.trustpilot.com/categories/hobbies_crafts?sort=reviews_count",
    "https://www.trustpilot.com/categories/education_training?sort=reviews_count",
    "https://www.trustpilot.com/categories/utilities?sort=reviews_count",
    "https://www.trustpilot.com/categories/public_local_services?sort=reviews_count",
    "https://www.trustpilot.com/categories/vehicles_transportation?sort=reviews_count",
    "https://www.trustpilot.com/categories/electronics_technology?sort=reviews_count"
]

MAX_SHOPS_PER_CATEGORY = 10     # æ¯ä¸ªåˆ†ç±»ä¸‹çˆ¬20ä¸ªåº—
TARGET_REVIEWS_PER_SHOP = 50   # æ¯ä¸ªåº—çˆ¬500æ¡

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Accept-Language': 'en-US,en;q=0.9'
}

def get_shops_from_category(category_url):
    base_url = category_url.split('?')[0]
    category_name = base_url.split('/')[-1]

    print(f"\næ­£åœ¨æ‰«æåˆ†ç±»: {category_name} ...")
    
    shop_links = []
    try:
        response = requests.get(category_url, headers=HEADERS)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, 'html.parser')
            links = soup.find_all('a', href=True)
            
            for link in links:
                href = link['href']
                if href.startswith('/review/') and 'trustpilot.com' not in href:
                    full_url = "https://www.trustpilot.com" + href
                    if full_url not in shop_links:
                        shop_links.append(full_url)
                    if len(shop_links) >= MAX_SHOPS_PER_CATEGORY:
                        break
        else:
            print(f"æ— æ³•è®¿é—®åˆ†ç±»é¡µé¢: {category_url}")
    except Exception as e:
        print(f"æ‰«æå‡ºé”™: {e}")
        
    print(f" -> åœ¨è¯¥åˆ†ç±»ä¸‹æ‰¾åˆ°äº† {len(shop_links)} ä¸ªåº—é“ºé“¾æ¥")
    return shop_links


def get_reviews_for_one_shop(shop_url, target_count):
    collected_reviews = []
    page_number = 1
    shop_name = shop_url.split('/')[-1]
    
    print(f"   [å¼€å§‹çˆ¬å–åº—é“º]: {shop_name}")

    while len(collected_reviews) < target_count:
        current_url = f"{shop_url}?page={page_number}"
        
        try:
            response = requests.get(current_url, headers=HEADERS)
            if response.status_code != 200:
                print(f"      é¡µé¢ {page_number} è®¿é—®å¤±è´¥æˆ–ç»“æŸ")
                break
                
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # --- ä¿®æ”¹é‡ç‚¹ï¼šæŸ¥æ‰¾ Review å¡ç‰‡ ---
            # Trustpilot çš„æ¯æ¡è¯„è®ºé€šå¸¸è¢«åŒ…è£¹åœ¨ <article> æ ‡ç­¾ä¸­
            review_cards = soup.find_all('article')
            
            if not review_cards:
                # å¦‚æœæ²¡æœ‰ article æ ‡ç­¾ï¼Œå¯èƒ½æ˜¯é¡µé¢ç»“æ„å˜äº†ï¼Œå°è¯•æ‰¾ç‰¹å®šçš„ div
                # ä½†ç›®å‰ Trustpilot ä¸»è¦æ˜¯ article
                print("      æœªæ‰¾åˆ°è¯„è®ºå¡ç‰‡ï¼Œå¯èƒ½å·²ç¿»é¡µåˆ°åº•ã€‚")
                break

            for card in review_cards:
                # 1. æå–æ˜Ÿæ˜Ÿè¯„åˆ†
                # é€šå¸¸æ˜¯ä¸€ä¸ª img æ ‡ç­¾ï¼Œalt å±æ€§å†™ç€ "Rated 5 out of 5 stars"
                star_rating = None
                star_img = card.find('img', alt=re.compile(r'Rated \d out of 5 stars'))
                
                if star_img:
                    alt_text = star_img['alt']
                    # æå–æ•°å­—
                    match = re.search(r'Rated (\d)', alt_text)
                    if match:
                        star_rating = int(match.group(1))
                
                # å¦‚æœæ‰¾ä¸åˆ° imgï¼Œå°è¯•æ‰¾ data-service-review-rating å±æ€§
                if star_rating is None:
                    rating_div = card.find('div', attrs={'data-service-review-rating': True})
                    if rating_div:
                        star_rating = int(rating_div['data-service-review-rating'])

                # 2. æå–è¯„è®ºæ–‡æœ¬
                # æŸ¥æ‰¾ç‰¹å®šçš„æ’ç‰ˆ p æ ‡ç­¾
                text_element = card.find('p', {'data-service-review-text-typography': 'true'})
                review_text = text_element.get_text(strip=True) if text_element else ""
                
                # åªæœ‰å½“æ˜Ÿæ˜Ÿå’Œæ–‡æœ¬è‡³å°‘æœ‰ä¸€ä¸ªå­˜åœ¨æ—¶æ‰ä¿å­˜
                # (æœ‰äº›è¯„è®ºå¯èƒ½åªæœ‰æ˜Ÿæ˜Ÿæ²¡æœ‰å­—ï¼Œæˆ–è€…åªæœ‰æ ‡é¢˜)
                if star_rating is not None:
                    # å¦‚æœæ²¡æœ‰æ­£æ–‡ï¼Œå°è¯•æ‰¾æ ‡é¢˜ (h2)
                    if not review_text:
                        title_element = card.find('h2', {'data-service-review-title-typography': 'true'})
                        if title_element:
                            review_text = title_element.get_text(strip=True)

                    collected_reviews.append({
                        'text': review_text,
                        'rating': star_rating
                    })
                
                if len(collected_reviews) >= target_count:
                    break
            
            page_number += 1
            time.sleep(random.uniform(1, 3))
            
        except Exception as e:
            print(f"      çˆ¬å–å‡ºé”™: {e}")
            break
            
    print(f"   -> å®Œæˆï¼Œå…±æŠ“å– {len(collected_reviews)} æ¡")
    return collected_reviews


if __name__ == "__main__":
    folder_name = "categories_data_small"
    if not os.path.exists(folder_name):
        os.makedirs(folder_name)

    for cat_url in TARGET_CATEGORIES:
        base_url = cat_url.split('?')[0] 
        cat_name = base_url.split('/')[-1]
        
        current_cat_data = [] 
        shops = get_shops_from_category(cat_url)
        
        for shop_url in shops:
            # è·å–çš„æ•°æ®ç°åœ¨æ˜¯å­—å…¸åˆ—è¡¨ [{'text':..., 'rating':...}]
            reviews_data = get_reviews_for_one_shop(shop_url, TARGET_REVIEWS_PER_SHOP)
            
            for item in reviews_data:
                current_cat_data.append({
                    'Category': cat_name, 
                    'Brand': shop_url.split('/')[-1],
                    'Review': item['text'],
                    'Star_Rating': item['rating'] # æ–°å¢ä¸€åˆ—
                })
            
            time.sleep(random.uniform(2, 5))
            
        if current_cat_data:
            filename = f"{folder_name}/reviews_{cat_name}.csv"
            df = pd.DataFrame(current_cat_data)
            # ç¡®ä¿ Review åˆ—æ˜¯å­—ç¬¦ä¸²ï¼Œé˜²æ­¢åç»­å¤„ç†æŠ¥é”™
            df['Review'] = df['Review'].fillna("")
            df.to_csv(filename, index=False)
            print(f"æˆåŠŸï¼åˆ†ç±» '{cat_name}' å·²ä¿å­˜ä¸º: {filename}")
        else:
            print(f"åˆ†ç±» '{cat_name}' æ²¡æœ‰æŠ“åˆ°æ•°æ®ã€‚")
            
        print("-" * 50)

    print(f"\nğŸ‰ æ‰€æœ‰åˆ†ç±»å…¨éƒ¨å¤„ç†å®Œæ¯•ï¼è¯·å» '{folder_name}' æ–‡ä»¶å¤¹æŸ¥çœ‹ç»“æœã€‚")