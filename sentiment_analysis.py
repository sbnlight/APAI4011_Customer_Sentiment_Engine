import pandas as pd
import os
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# é¦–æ¬¡è¿è¡Œæ—¶éœ€è¦ä¸‹è½½è¯å…¸

try:
    nltk.data.find('sentiment/vader_lexicon.zip')
except LookupError:
    print("æ­£åœ¨ä¸‹è½½ VADER è¯å…¸...")
    nltk.download('vader_lexicon')

def analyze_sentiment_and_score():
    # è¾“å…¥æ–‡ä»¶å¤¹ï¼ˆçˆ¬è™«ç”Ÿæˆçš„æ•°æ®ï¼‰
    input_folder = "categories_data_small"
    # è¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆå¤„ç†åçš„æ•°æ®ï¼‰
    output_folder = "data_with_sentiment_score"
    
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æå™¨
    sid = SentimentIntensityAnalyzer()

    # æƒé‡è®¾ç½®
    WEIGHT_USER_RATING = 0.5
    WEIGHT_TEXT_SENTIMENT = 0.5

    print(f"å¼€å§‹å¤„ç†æ–‡ä»¶å¤¹ '{input_folder}' ä¸­çš„æ–‡ä»¶...\n")

    # éå†æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰ CSV æ–‡ä»¶
    files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]
    
    if not files:
        print(f"é”™è¯¯ï¼šåœ¨ '{input_folder}' ä¸­æ²¡æœ‰æ‰¾åˆ° CSV æ–‡ä»¶ã€‚è¯·å…ˆè¿è¡Œçˆ¬è™«ã€‚")
        return

    for file in files:
        input_path = os.path.join(input_folder, file)
        print(f"æ­£åœ¨å¤„ç†: {file} ...")

        try:
            df = pd.read_csv(input_path)
            
            # ç¡®ä¿ Review åˆ—æ˜¯å­—ç¬¦ä¸²ï¼Œå¤„ç†ç©ºå€¼
            df['Review'] = df['Review'].fillna("").astype(str)
            
            # å­˜å‚¨è®¡ç®—ç»“æœçš„åˆ—è¡¨
            sentiment_scores_raw = [] # VADER åŸå§‹åˆ† (-1 åˆ° 1)
            sentiment_stars = []      # VADER è½¬æ¢åçš„æ˜Ÿçº§ (1 åˆ° 5)
            weighted_scores = []      # æœ€ç»ˆåŠ æƒåˆ†

            for index, row in df.iterrows():
                text = row['Review']
                user_rating = row['Star_Rating']
                
                # 1. è¿›è¡Œæƒ…æ„Ÿåˆ†æ
                # å¦‚æœæ–‡æœ¬å¤ªçŸ­ï¼ˆä¾‹å¦‚åªæœ‰å‡ ä¸ªå­—ï¼‰ï¼ŒVADER å¯èƒ½ä¸å‡†ï¼Œä½†å®ƒæ˜¯ç›®å‰æœ€é€šç”¨çš„æ–¹æ¡ˆ
                if len(text.strip()) > 0:
                    ss = sid.polarity_scores(text)
                    compound_score = ss['compound'] # è·å–ç»¼åˆå¾—åˆ† (-1 ~ 1)
                else:
                    # å¦‚æœæ²¡æœ‰æ–‡å­—ï¼Œæƒ…æ„Ÿå¾—åˆ†é»˜è®¤ä¸ºä¸­æ€§ 0
                    compound_score = 0.0

                # 2. å°†æƒ…æ„Ÿåˆ†æ•°æ˜ å°„åˆ° 1-5 æ˜Ÿ
                # logic: -1 -> 1æ˜Ÿ, 0 -> 3æ˜Ÿ, +1 -> 5æ˜Ÿ
                # linear mapping formula: y = 2x + 3
                # x=-1, y=1; x=0, y=3; x=1, y=5
                predicted_star = 2 * compound_score + 3
                
                # é™åˆ¶èŒƒå›´åœ¨ 1-5 ä¹‹é—´ (è™½ç„¶æ•°å­¦ä¸Šä¸ä¼šè¶…ï¼Œä½†ä¿é™©èµ·è§)
                predicted_star = max(1.0, min(5.0, predicted_star))

                # 3. è®¡ç®—åŠ æƒå¹³å‡
                # ç»“åˆ ç”¨æˆ·æ‰“åˆ† (user_rating) å’Œ æ–‡æœ¬åˆ†ææ¨æ–­åˆ† (predicted_star)
                final_score = (user_rating * WEIGHT_USER_RATING) + (predicted_star * WEIGHT_TEXT_SENTIMENT)

                sentiment_scores_raw.append(round(compound_score, 4))
                sentiment_stars.append(round(predicted_star, 2))
                weighted_scores.append(round(final_score, 2))

            # å°†ç»“æœå†™å› DataFrame
            df['Sentiment_Raw_Score'] = sentiment_scores_raw # VADERåŸå§‹åˆ†
            df['Sentiment_Implied_Rating'] = sentiment_stars # æ ¹æ®æ–‡å­—æ¨æ–­çš„æ˜Ÿçº§
            df['Final_Weighted_Score'] = weighted_scores     # åŠ æƒåçš„æœ€ç»ˆå¾—åˆ†

            # ä¿å­˜åˆ°æ–°æ–‡ä»¶å¤¹
            output_path = os.path.join(output_folder, f"analyzed_{file}")
            df.to_csv(output_path, index=False)
            print(f" -> å·²ä¿å­˜ç»“æœåˆ°: {output_path}")

        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {file} æ—¶å‡ºé”™: {e}")

    print(f"\nğŸ‰ æ‰€æœ‰åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ '{output_folder}' æ–‡ä»¶å¤¹ã€‚")

if __name__ == "__main__":
    analyze_sentiment_and_score()